{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2844ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em ../datasets/edges.csv\n",
      "     src   dest       rssi       etx      delay  busy_fraction  label\n",
      "0  51679   4099 -52.240193  3.213027  29.192350       0.273040      1\n",
      "1   5598  97030 -65.528683  9.078898  54.702416       0.385090      0\n",
      "2  98247  27356 -57.386371  3.047537  31.362661       0.311230      1\n",
      "3  59679  62407 -60.366136  1.981208  32.438587       0.193277      1\n",
      "4  56906  71176 -73.647850  5.488077  41.922475       0.776727      0\n",
      "\n",
      "Distribuição dos labels:\n",
      "label\n",
      "1    100000\n",
      "0    100000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run 1.dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ace084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.6177, Train Acc 0.5618, Test Acc 0.9068\n",
      "Epoch 10, Loss 0.2960, Train Acc 0.9688, Test Acc 0.9691\n",
      "Epoch 20, Loss 0.1142, Train Acc 0.9766, Test Acc 0.9768\n",
      "Epoch 30, Loss 0.0608, Train Acc 0.9809, Test Acc 0.9815\n",
      "Epoch 40, Loss 0.0452, Train Acc 0.9840, Test Acc 0.9843\n",
      "\n",
      "Acurácia final no conjunto de teste: 0.9858\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[29315   685]\n",
      " [  166 29834]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Ruim       0.99      0.98      0.99     30000\n",
      "         Bom       0.98      0.99      0.99     30000\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "Modelo salvo em ../models/mlp.pth\n",
      "Modelo salvo em ../models/scaler.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# ====== Carregar dataset ======\n",
    "df = pd.read_csv(\"../datasets/edges.csv\")\n",
    "\n",
    "X = df[[\"rssi\", \"etx\", \"delay\", \"busy_fraction\"]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# ====== Definir Modelo MLP ======\n",
    "class LinkMLP(nn.Module):\n",
    "    def __init__(self, in_dim=4, hidden=16, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = LinkMLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# ====== Treinamento ======\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        pred_train = out.argmax(dim=1)\n",
    "        acc_train = (pred_train == y_train).float().mean().item()\n",
    "        pred_test = model(X_test).argmax(dim=1)\n",
    "        acc_test = (pred_test == y_test).float().mean().item()\n",
    "        print(f\"Epoch {epoch}, Loss {loss.item():.4f}, \"\n",
    "              f\"Train Acc {acc_train:.4f}, Test Acc {acc_test:.4f}\")\n",
    "\n",
    "# ====== Avaliação final ======\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test)\n",
    "    pred_test = logits.argmax(dim=1)\n",
    "\n",
    "# Acurácia\n",
    "acc_test = (pred_test == y_test).float().mean().item()\n",
    "print(f\"\\nAcurácia final no conjunto de teste: {acc_test:.4f}\")\n",
    "\n",
    "# Métricas adicionais\n",
    "y_true = y_test.numpy()\n",
    "y_pred = pred_test.numpy()\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Ruim\", \"Bom\"]))\n",
    "\n",
    "# ====== Salvar modelo ======\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/mlp.pth\")\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "\n",
    "print(\"Modelo salvo em ../models/mlp.pth\")\n",
    "print(\"Modelo salvo em ../models/scaler.pkl\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
